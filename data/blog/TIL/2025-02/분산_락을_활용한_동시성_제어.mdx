---
title: '분산 락을 활용한 동시성 제어'
date: '2025-07-25'
tags: ['프로젝트', 'Redis', '좋아요', '캐싱', '분산 락']
draft: false
summary: 'Redisson 분산 락으로 좋아요 기능의 동시성 문제를 해결한 과정과 고민을 공유합니다.'
---

### Introduction

<TOCInline toc={props.toc} exclude="Introduction" />

좋아요 기능에서 마주한 동시성 문제와 해결 과정을 공유합니다. "좋아요 버튼 하나쯤이야 간단하지 않나?"라고 생각했지만, 실제로는 중복 클릭, 분산 환경, 트랜잭션 충돌 등 예상보다 복잡한 문제들이 있었습니다.

이번 글에서는 Redis 분산 락(Redisson)을 활용해 어떻게 이런 문제들을 해결했는지, 왜 이런 결정을 내렸는지, 실제 성능은 어떻게 개선되었는지에 대해 설명하겠습니다.

## 어떻게 문제 상황을 마주하게 되었나?

### 초기 단순한 구현

좋아요 기능을 처음 만들 때는, 오히려 고민이 없었다. 너무나 익숙하고 직관적인 기능이었기 때문이다. 단순히 존재 여부에 따라 insert/delete만 반복하면 되는 줄 알았다.

처음에는 가장 직관적인 방식으로 좋아요 기능을 구현했다. 특별한 예외처리나 방어 로직이 필요하다고 생각하지 않았다. 그러다 보니 “이게 뭐가 문제지?”라는 태도로 접근했고, 실제로도 사용자 수가 적을 땐 문제가 없었기에 더더욱 방심했다.

```java
@Transactional
public LikeStatus updateLikeStatus(Long articleId, Long memberId) {
    Member member = memberService.findMemberById(memberId);
    Article article = findArticleById(articleId);
    
    Optional<ArticleLike> existingLike = 
        articleLikeRepository.findByArticleAndMember(article, member);
    
    if (existingLike.isPresent()) {
        articleLikeRepository.delete(existingLike.get());
        return LikeStatus.LIKE_REMOVED;
    }
    
    articleLikeRepository.save(ArticleLike.create(article, member));
    return LikeStatus.LIKE_ADDED;
}
```

좋아요 기능은 단순한 토글 기능이니까 문제없을거라고 생각했다.

- 토글 : 한번 누르면 좋아요 → 다시 한번 더 누르면 좋아요 취소 → 반복

좋아요 기능을 처음 도입했을 당시에는 큰 문제는 없었다.

동시에 좋아요 요청이 들어오는 경우도 거의 없었고 사용자가 버튼을 눌렀을 때 즉시 반응했고, 데이터 정합성에도 전혀 문제가 없었다. 그 시점까지만 해도 “지금 구현 방식이면 충분하겠다?”고 생각했다.

기능 자체도 단순했고, 특별히 예외 처리를 고민할 필요도 없었다. 하지만 이 모든 건 어디까지나 사용자가 적을 때 이야기다.

<br/>

## 언제부터 문제가 생겼나?

![image.png](/static/images/image228.png)

서비스에 점점 유입이 늘면서 문제가 나타났다. 특히, 인기 게시글이 생기고, 사용자들이 빠르게 반응할 때였고, 예상치 못한 동시성 문제가 생겼다. 사용자들은 “좋아요를 눌렀는데 반응이 없다”고 느끼면 어떻게 행동할까? → 다시 누른다. 그리고 또 누른다.

문제가 생겼다는 걸 인지하고 나서 가장 먼저 한 건, “기존 구조에서 어떤 부분이 병목일까?“를 찾는 일이었다.

인기 게시글 + 빠른 클릭 패턴이 문제의 핵심이었다. 또한 네트워크 지연 같은 느린 응답으로 인한 중복 요청이 문제였다.

### 실제 로그를 보면

```java
2025-07-15 14:23:45.123 - Member[123] 게시글[456] 좋아요 요청
2025-07-15 14:23:45.135 - Member[123] 게시글[456] 좋아요 요청 (중복!)
2025-07-15 14:23:45.142 - Member[123] 게시글[456] 좋아요 요청 (중복!)
```

같은 사용자의 좋아요가 2개 생성됨 (DB 제약조건 위반)

네트워크 지연이나 화면 딜레이로 인해, 같은 사용자가 0.02초 간격으로 좋아요 요청을 세 번이나 보내는 상황이 실제로 자주 발생했다.

<br/>

## 동시성 문제를 진짜로 이해하기까지

처음엔 DB 제약조건이 중복 좋아요 삽입을 막아주고 있었기 때문에 “에러가 나긴 해도 괜찮다”라고 생각했다.

그런데 로그를 하나하나 뜯어보면서 “한 명의 유저가 수백 번의 롤백을 유발하고 있다”는 사실을 깨달았고, 이건 무시할 수 없는 비용이라고 생각했다.

가장 어려웠던 건, 이 문제가 눈앞에서 재현되기 어렵다는 점이었다.

내가 직접 누르면 정상 동작하는데, 사용자들이 연달아 눌렀을 때만 문제가 생긴다.

그래서 직접 부하 테스트 스크립트를 짜서, 같은 요청을 초당 수십 건씩 보내봤다.

### 데이터 정합성 오류

```java
// 두 요청이 동시에 들어올 때
Request A: SELECT * FROM article_like WHERE article_id=1 AND member_id=2
Request B: SELECT * FROM article_like WHERE article_id=1 AND member_id=2

// 둘 다 "좋아요가 없다"고 판단
Request A: INSERT INTO article_like (article_id, member_id) VALUES (1, 2)
Request B: INSERT INTO article_like (article_id, member_id) VALUES (1, 2)
```

결과: 같은 사용자의 좋아요가 2개 생성됨 (DB 제약조건 위반)

- Unique 제약조건 덕분에 중복 데이터는 막을 수 있었지만, 사용자에게는 에러가 노출되었다.

### 불필요한 서버 리소스 소모

```java
// 동시 요청으로 인한 DB 부하
SELECT 쿼리 × 3번
INSERT 시도 × 3번 (2번은 실패)
트랜잭션 롤백 × 2번
```

같은 작업을 여러 번 시도하면서 불필요한 DB 커넥션과 CPU를 사용하고 있었다.

- 동시 요청 하나가, 서버 입장에서는 3배의 비용이 드는 구조가 되어버렸다.

<br/>

## 기존 해결책들에 대한 고민

![image.png](/static/images/image229.png)

```java
"Unique 제약조건으로 충분하지 않나?"
```

- 중복 데이터는 막을 수 있지만 사용자에게 에러 노출
- SELECT-INSERT 구조의 낭비는 여전히 존재
- 롤백 비용도 만만치 않다고 들었다..

```java
"@Transactional 격리 수준을 높이면?"
```

- SERIALIZABLE 수준으로 하면 해결될 수 있지만 전체 DB 성능 저하가 너무 크고, 병목이 생긴다
- 과도한 성능이 발생할 수 있다.

```java
"synchronized 키워드는?"
```

처음에는 synchronized 키워드를 걸까 고민했다. 하지만 서비스가 커진다면 여러 서버로 확장될 것인데, 이 방법은 단일 서버에서만 효과가 있었다.

- 단일 서버에선 동작하지만, 분산 서버 환경에선 무의미하다.
- 전체 메서드가 블로킹되어 성능 저하된다.

```java
"메모리 기반 중복 방지는?"
```

인스턴스 간 공유가 되지 않기 때문에 확장성도 없고, 서버 재시작 시 유실될 위험도 컸다.

- 서버가 2대 이상이면 각각의 메모리는 따로 존재
- 확장성이 없고, 서버 재시작 시 유실 위험

결국, 이중 아무것도 “현실적인” 해결책이 아니었다.

<br/>

## 분산 락을 선택하기까지

분산 락이라는 개념은 알고 있었지만, “좋아요 같은 가벼운 기능에 과한 게 아닐까?“라는 생각이 계속 맴돌았다.

하지만 문제가 ‘좋아요’라는 기능 자체에 있는 게 아니라, “유저의 반복적인 액션과 시스템 처리 방식의 비동기성 충돌”에 있다는 걸 깨닫고 나서야 결정을 내릴 수 있었다.

- 이미 캐싱용으로 Redis를 사용하고 있었고, 분산 환경 확장성이 중요했기 때문에 Redis 분산 락을 선택했다.

### 그 중에서도 Redisson을 선택한 이유는

- 직접 Lua 스크립트 작성 없이도 락 보장이 가능하고
- WatchDog 기능으로 예외 상황에서도 락 자동 해제가 되는 점
- Spring Boot 환경에서의 통합이 매끄럽다는 점

내부적으로는 락 범위를 어디까지 좁힐 수 있을까도 많이 고민했다.

처음에는 articleId 단위로 락을 걸었는데, 이러면 같은 게시글에 대해 여러 사용자가 동시에 좋아요를 누르면 병렬 처리가 막힌다. 그래서 결국 articleId + memberId 조합으로 조정해, 최소한의 블로킹 범위로 구성했다.

### 분산 락의 장점

- 멀티 서버 환경 대응: Redis를 중앙 저장소로 사용
- 특정 제어: 특정 리소스에 대해서만 락 적용
- 타임아웃 기능: 데드락 방지와 성능 보장
- 운영 안정성: 락 해제 보장 메커니즘

### Redis vs DB 락 vs 메모리 락

| 구분 | Redis 분산 락 | DB 락 | 메모리 락 |
| --- | --- | --- | --- |
| 분산 환경 | 지원 | 지원 | 단일 서버만 지원 |
| 성능 | 빠름 | 보통 | 매우 빠름 |
| 타임아웃 | 지원 | 제한적 | 지원 |
| 구현 복잡도 | 보통 | 간단 | 간단 |
| 인프라 의존성 | Redis 필요 | 없음 | 없음 |

<br/>

## Redisson 도입과 분산 락 구현

분산 락 구현체로 Redisson을 선택한 이유는 무엇인가?

```java
"순수 Redis 명령어 vs Redisson?"
```

순수 Redis: `SET key value NX EX 30` 방식

- 구현이 단순하지만 락 해제 로직이 복잡하다.
- 다양한 엣지 케이스 직접 처리 필요

Redisson 사용 이유

- Spring Boot와 통합 용이
- 자동 락 갱신 기능
- 예외 상황에서도 락 해제 보장
- 다양한 락 타입 지원 (Read/Write Lock 등)


## 락 키 설계

![image.png](/static/images/image230.png)

![image.png](/static/images/image231.png)

```java
lock:like:article:{articleId}:member:{memberId}
```

- 게시글 + 사용자 단위로 세분화
- 불필요한 블로킹 방지
- 명확한 키 네이밍으로 디버깅 편의성

### 타임아웃 전략 고민

```java
LOCK_WAIT_TIME = 3초   // 락을 최대 3초까지 기다림
LOCK_LEASE_TIME = 1초  // 락을 1초 보유
```

- 1초는 너무 짧아 실패율 높다
- 5초는 사용자 경험상 길게 느껴짐
- 3초가 실패율 2%로 안정적이면서도 UX에 무리 없음

### 실제 구현 과정

```java
@Service
@RequiredArgsConstructor
public class ArticleLikeService {

    private final ArticleLikeRepository articleLikeRepository;
    private final ArticleRepository articleRepository;
    private final RedissonClient redissonClient;
    private final MemberService memberService;

    private static final long LOCK_WAIT_TIME = 3L;    // 락 획득 대기 시간
    private static final long LOCK_LEASE_TIME = 1L;   // 락 보유 시간

    @Transactional
    public LikeStatus updateLikeStatus(Long articleId, Long memberId) {
        String lockKey = RedisKey.articleLikeLockKey(articleId, memberId);
        RLock lock = redissonClient.getLock(lockKey);

        boolean lockAcquired = false;
        try {
            // 락 획득 시도 (3초 대기, 1초 보유)
            lockAcquired = lock.tryLock(LOCK_WAIT_TIME, LOCK_LEASE_TIME, TimeUnit.SECONDS);
            if (!lockAcquired) {
                throw new ArticleException(ArticleError.CONCURRENT_LIKE_REQUEST);
            }
            
            return addOrRemoveLike(articleId, memberId);
            
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new ArticleException(ArticleError.LOCK_INTERRUPTED);
        } finally {
            // 락 해제 (안전한 해제)
            if (lockAcquired && lock.isHeldByCurrentThread()) {
                lock.unlock();
            }
        }
    }

    @Transactional(readOnly = true)
    public long countLikes(Long articleId) {
        Article article = articleRepository.findById(articleId)
                .orElseThrow(() -> new ArticleException(ArticleError.ARTICLE_NOT_FOUND));
        return articleLikeRepository.countByArticle(article);
    }

    private LikeStatus addOrRemoveLike(Long articleId, Long memberId) {
        Member member = memberService.findMemberById(memberId);
        Article article = articleRepository.findById(articleId)
                .orElseThrow(() -> new ArticleException(ArticleError.ARTICLE_NOT_FOUND));

        Optional<ArticleLike> likeOptional = 
            articleLikeRepository.findByArticleAndMember(article, member);
            
        if (likeOptional.isPresent()) {
            articleLikeRepository.delete(likeOptional.get());
            return LikeStatus.LIKE_REMOVED;
        }

        articleLikeRepository.save(ArticleLike.create(article, member));
        return LikeStatus.LIKE_ADDED;
    }
}
```

### 락 키 전략과 Redis Key 관리

```java
// RedisKey 클래스에서 락 키 관리
public static String articleLikeLockKey(Long articleId, Long memberId) {
    return String.format("lock:like:article:%s:member:%s", articleId, memberId);
}
```

락 키 설계 원칙

- 사용자별 + 게시글별: `lock:like:article:123:member:456`
- 자세한 단위: 다른 게시글 좋아요는 블로킹하지 않는다.
- 명확한 네이밍: 용도와 범위를 키에서 바로 파악 가능하다.

<br/>

## 성능 개선과 락 전략 고민

```java
"LOCK_WAIT_TIME를 얼마로 설정할까?"
```

- 1초: 너무 짧음. 네트워크 지연으로 정상 요청도 실패할 수 있음
- 10초: 너무 김. 사용자가 기다리기에는 너무 오래
- 3초: (결정) 네트워크 지연을 고려하되 사용자 경험을 해치지 않는 선

```java
"LOCK_LEASE_TIME을 얼마로 설정할까?"
```

- 좋아요 로직 수행 시간: DB 조회 + 삽입/삭제 ≈ 500ms
- 안전 마진: 네트워크 지연과 예외 상황 고려
- 1초: 충분한 여유를 두되 불필요하게 길지 않게

### 실제 테스트 결과

```java
100회 동시 좋아요 요청 시:
- WAIT_TIME 1초: 실패율 23%
- WAIT_TIME 3초: 실패율 2%  ← 선택
- WAIT_TIME 5초: 실패율 0%, 하지만 평균 응답시간 증가
```

```java
"락 획득 실패 시 어떻게 응답할까?"
```

- 에러 반환: 사용자에게 "잠시 후 다시 시도해주세요"
- 재시도: 자동으로 몇 번 더 시도
- 대기: 락이 해제될 때까지 기다림

결정: 명확한 에러 메시지로 사용자에게 알림

- 사용자가 상황을 이해할 수 있도록 도움
- 시스템 부하를 줄임 (무한 재시도 방지)
- 빠른 피드백으로 사용자 경험 개선

```java
// ArticleError enum에서 정의된 에러 메시지들
CONCURRENT_LIKE_REQUEST("동시에 여러 번 좋아요를 누르셨습니다. 잠시 후 다시 시도해주세요."),
LOCK_INTERRUPTED("요청 처리 중 오류가 발생했습니다.")
```

<br/>

## 실제 성능 개선 결과

![image.png](/static/images/image232.png)

### 부하 테스트 비교

```java
# 동일 조건 부하 테스트 (1000명이 동시에 같은 게시글 좋아요)

Before (분산 락 없이):
- 성공률: 67%
- 평균 응답시간: 850ms  
- DB 에러율: 33%
- 중복 데이터 생성: 평균 15건/테스트

After (Redisson 분산 락):
- 성공률: 98%
- 평균 응답시간: 420ms (51% 개선)
- DB 에러율: 0%
- 중복 데이터 생성: 0건
- 락 획득 실패: 2% (명확한 안내 메시지)
```

분산 락 도입으로 인한 Redis 부하 증가는 미미했지만, 비즈니스 로직의 안정성은 크게 개선되었다.

## 분산 락 도입 시 고려사항

### 성능 vs 정합성 트레이드오프

| 구분 | 분산 락 | DB 제약조건 | 애플리케이션 검증 |
| --- | --- | --- | --- |
| 정합성 | 완벽함 | 에러 발생 | 불완전 |
| 성능 | 네트워크 비용 | 빠름 | 매우 빠름 |
| 복잡도 | 높음 | 낮음 | 낮음 |
| 확장성 | 분산 환경 | 분산 환경 | 단일 서버 |

### 언제 분산 락을 사용해야 하나?

- 동시성으로 인한 비즈니스 로직 오류가 발생
- DB 제약조건만으로는 사용자 경험이 나쁨
- 분산 환경에서 동시성 제어 필요
- 복잡한 비즈니스 룰이 있는 경우

분산 락이 과도한 경우는?

- 단순한 CRUD 작업
- 성능이 매우 중요한 고빈도 작업
- 단일 서버 환경
- DB 레벨 해결책이 충분한 경우

```java
// 락 설계 (실제 프로젝트)
"lock:like:article:123:member:456"  // 세밀한 범위, 명확한 의미

// 피해야 할 락 설계  
"lock:article:123"                  // 너무 넓은 범위
"lock:user:456"                     // 모호한 의미
"mylock:abc123"                     // 불명확한 네이밍
```

<br/>

## 마무리와 교훈

사실 처음에는 “굳이 락까지 써야 하나?“라는 생각이 컸습니다.

하지만 실제 사용자 행동 패턴, DB 부하 로그를 하나하나 살펴보면서, 내가 지금까지 얼마나 서버 사이드 로직을 낙관적으로 바라보고 있었는지 돌아보게 됐습니다.

분산 락 도입을 통해 98% 성공률과 51% 응답시간 개선이라는 수치적 성과도 중요하지만, 더 중요한 것은 이 과정에서 배운 동시성 제어에 대한 체계적 접근법입니다.

"동시성 문제"라고 뭉뚱그리지 말고, 구체적으로 어떤 시나리오에서 어떤 문제가 발생하는지 명확히 파악해야 한다는 것을 느꼈다. 또한 처음부터 완벽한 분산 락을 도입하는 것보다, DB 제약조건 → 애플리케이션 검증 → 분산 락 순으로 점진적 개선이 효과적라는 것.

모든 곳에 분산 락을 적용하는 것은 과도하다고 생각한다. 비즈니스 영향도와 기술적 복잡성을 고려한 선택이 필요하다. 이론적인 동시성 문제뿐만 아니라, 연속 클릭, 네트워크 지연으로 인한 중복 요청 등 실제 환경에서 발생하는 패턴을 반영해야 한다.