---
title: '실시간 캐싱, 지연 동기화로 조회수 성능 개선'
date: '2025-07-23'
tags: ['프로젝트', 'Redis', '조회수', '캐싱', '지연동기화']
draft: false
summary: 'Redis 기반 실시간 캐싱과 지연 동기화로 조회수 시스템의 성능 병목을 개선한 과정과 고민을 공유합니다.'
---

### Introduction

<TOCInline toc={props.toc} exclude="Introduction" />


개발자 커뮤니티 DevLink를 운영하면서 조회수 시스템의 성능 문제를 마주하게 되었습니다. 초기에는 단순한 DB 업데이트로 시작했지만, 사용자가 늘어나면서 성능 저하를 경험했습니다.

이 글은 실시간 캐싱 + 지연 동기화 아키텍처로 문제를 해결한 과정과 그 과정에서의 고민들을 작성하였습니다. 왜 이런 결정을 내렸는지, 어떤 대안들을 고민했는지, 실제로 어떤 효과가 있었는지에 대해 설명하겠습니다.

<br/>

## 어떻게 문제 상황을 마주하게 되었나?

![image.png](/static/images/이미지215.png)

### 초기 단순한 구현

처음에는 가장 간단한 방식으로 조회수를 구현했다.

```java
@Transactional
public ArticleDetailResponse findDetail(Long articleId, Long memberId) {
    Article article = articleRepository.findById(articleId)
        .orElseThrow(() -> new ArticleException(ArticleError.ARTICLE_NOT_FOUND));
    
    // 매번 DB 업데이트
    article.incrementViewCount();
    articleRepository.save(article);
    
    return ArticleDetailResponse.from(article);
}
```

"조회수쯤이야 간단하게 DB에서 바로 처리하면 되겠지?”

초기에는 정말 문제없었다.

```java
-- 사용자 50명 시절의 하루 통계
총 게시글 조회: 500회
동시 접속 최대: 10명
평균 응답시간: 80ms
DB CPU 사용률: 15%
```

이 정도 트래픽이면 어떤 구조든 잘 돌아간다.

사실 이 시점에서 “과도한 설계보다, 단순한 구현이 더 낫다”고 믿고 있었다. 실제로도 문제는 없었다.

지금 돌아보면, 단순한 구조를 선택한 건 틀리지 않았지만, 변화에 유연하지 못한 구조였다는 것이 문제였다.

### 문제는 언제부터 발생했는가?

- 사용자 증가: 동시 접속자 50명 → 200명
- 인기 게시글: 특정 게시글에 트래픽 집중
- 웹 페이지: 새로고침으로 인한 중복 조회 급증

예상했던 패턴으로는 사용자가 게시글을 차근차근 읽고 다음 글로 이동하는 것이었으며,

실제 사용 패턴은 사용자가 여러 탭을 열어두고 빠르게 브라우징, 새로고침을 자주 누름, 뒤로가기 후 다시 들어오는 상황이 있었다.

<br/>

## 이게 왜 문제인가?

### DB 성능 저하 (=DB UPDATE 충돌)

```sql
-- 매 조회마다 발생하는 쿼리들
SELECT * FROM article WHERE id = 1;
UPDATE article SET view_count = view_count + 1 WHERE id = 1;
```

인기 게시글 하나에 100명이 동시 접근하면 100개의 UPDATE 쿼리가 동시에 실행된다.

- 100개의 트랜잭션이 같은 행을 수정하려고 대기한다.
- 첫 번째 트랜잭션이 완료될 때까지 나머지 99개는 블록킹 상태이다.
- 결과적으로 순차 처리가 되어 응답시간이 급증한다.

여러 사용자가 동시에 읽는 상황에서 조회수가 병목이 될 수 있다는 걸 처음 실감했다.

### 응답 시간 지연

처음엔 DB 성능만 문제인 줄 알았지만, 실제로 사용자들이 “게시글이 너무 느리게 열린다”는 반응을 보이기 시작했다. 게시글이 너무 느리게 열렸고, 클릭하면 한참 기다려야 하는 문제가 발생했었다.

```java
게시글 클릭 → 서버 요청(50ms) 
→ DB SELECT(80ms) 
→ UPDATE 대기(1200ms) ← 병목 발생
→ 응답 생성(30ms)
→ 렌더링(100ms) → 총 1.5초
```

응답 시간 1.5초, 게시글 하나 열기 위해 1.5초가 걸리는 상황이었다.

- 동시 사용자 50명: 괜찮음
- 동시 사용자 100명: 조금 느림
- 동시 사용자 200명: 명확한 지연
- 동시 사용자 500명: 타임아웃 발생

<br/>

## 문제를 어떻게 감지했는지?

![image.png](/static/images/이미지216.png)

### 직접 측정해봤다 (JMeter 테스트)

```sql
# JMeter로 부하 테스트
100명이 동시에 같은 게시글 조회
→ 평균 응답시간: 2.3초
→ 에러율: 15%
→ DB CPU 사용률: 85%
```

조회수 업데이트가 실시간으로 이루어질 필요는 없지만, 너무 늦어도 안된다는 기준을 세웠다.

### 모니터링 도구

```sql
2025-07-10 14:23:01 - SELECT * FROM article WHERE id = 123
2025-07-10 14:23:01 - UPDATE article SET view_count = 45 WHERE id = 123
2025-07-10 14:23:01 - SELECT * FROM article WHERE id = 123
2025-07-10 14:23:01 - UPDATE article SET view_count = 46 WHERE id = 123
2025-07-10 14:23:02 - SELECT * FROM article WHERE id = 123
2025-07-10 14:23:02 - UPDATE article SET view_count = 47 WHERE id = 123
```

같은 게시글에 UPDATE 쿼리가 초당 수십 개씩 실행되고 있다..

<br/>

## 해결 과정: 단계별 개선

![image.png](/static/images/이미지217.png)

### 메모리 기반 배치 처리

처음 떠오른 아이디어는 “*DB 업데이트를 모아서 한 번에 처리하면 어떨까?"* 였다.

- “그냥 조회수를 한 번에 모아서 일정 주기로 저장하면 되잖아?”

그래서 간단한 ConcurrentHashMap + AtomicLong 조합으로 구현했다.

```java
// 1차 개선: 메모리에 모았다가 배치 처리
private final Map<Long, AtomicLong> viewCountBuffer = new ConcurrentHashMap<>();

public void addViewCount(Long articleId) {
    viewCountBuffer.computeIfAbsent(articleId, k -> new AtomicLong(0))
                   .incrementAndGet();
}

@Scheduled(fixedRate = 60000) // 1분마다
public void flushViewCounts() {
    viewCountBuffer.forEach((articleId, count) -> {
        articleRepository.incrementViewCount(articleId, count.get());
    });
    viewCountBuffer.clear();
}
```

조금 나아졌지만 여전히 문제가…해결되지는 않았다.

<br/>

## 이 시점의 고민

```java
"스케줄링 주기를 얼마로 설정할까?"
```

- 30초? → 너무 자주 실행
  - 테스트 결과 Redis에 있는 조회수 변화량이 작을 때에도 쿼리가 실행되어, 오히려 DB에 잦은 write가 발생한다. (DB 부하를 줄이려는 목적과 상충)
- 5분? → 실시간성 떨어짐
  - 사용자 입장에서 ‘방금 본 글의 조회수’가 계속 고정되어 보이는 현상
- 1분? → (결정) 적당한 균형점
  - 1분 안에 하나의 인기 글에 50~100명의 조회가 몰리는 경우가 있다.
  - 이 정도면 조회수 업데이트를 지연해도 사용자가 체감하는 “실시간성”은 유지된다고 생각한다.
  - 동시에 DB 입장에서는 1분에 한 번의 배치 업데이트는 충분히 감당 가능 (트래픽 대비 안정적)

즉, 1분이라는 주기는 실시간성과 DB 안정성 사이의 균형점이라고 생각했습니다.

- 사용자 입장에서는 ‘조회수 반영 안 됐네?’라고 느끼지 않음
- 시스템 입장에서는 Redis 캐시로 충분히 버퍼링 가능
- 랭킹 알고리즘 등 다른 실시간 기능에도 영향 없이 반영 가능

```java
"동시성 처리는 어떻게 할까?"
```

- synchronized?
  - 한 스레드만 접근 가능하게 만들어 race condition은 막을 수 있다
  - 하지만 조회수는 요청 빈도가 높은 로직이라, synchronized를 걸면 그 시점에 하나의 스레드만 접근 가능 → 병렬성이 사라짐
  - 특히 flush 주기 내에 수천 개의 조회가 발생하면 락 경쟁이 발생하여 성능이 떨어진다.
- ConcurrentHashMap + AtomicLong?
  - `ConcurrentHashMap`은 segment 단위로 동기화되어 여러 쓰레드가 동시에 다른 키에 접근 가능하다.
  - `AtomicLong`은 내부적으로 CAS를 사용하여 lock-free 방식으로 안전한 증가 연산 보장한다.
  - 두 가지 조합을 사용하면, 락 없이도 안전하게 카운팅 가능하면서 성능도 좋다.

### 적용 결과

- 응답시간: 2.3초 → 0.8초 (65% 개선)
- DB 업데이트 쿼리: 90% 감소

### 하지만 새로운 문제들

- 서버 재시작 시 데이터 유실 : 메모리에 있던 조회수가 날아간다.
- 여러 서버가 있다면? 서로 카운트를 공유하지 못한다.
- 실시간성 부족 : 1분간은 조회수가 반영 안된다.
- 중복 조회를 계속해서 카운트하는 문제가 생겼다.

이쯤 되자 “근본적인 구조 변화가 필요하다”는 생각이 들었다.

<br/>

## Redis 도입, 하지만 망설였다.

Redis를 바로 떠올렸지만, 솔직히 망설였다.

- 이유는 인프라 복잡성 증가하는 것이였고, 과연 단순 조회수에 Redis를 써야 하나? 싶은 생각이 컸다.

```java
"Redis말고 다른 방법은 없을까?"
```

- DB 최적화? → 근본적 해결책이 아니라고 판단했다.
- 조회수를 포기? → 사용자 경험상 불가능하다.
- MongoDB 같은 NoSQL 도입? → 너무 과도한 변경

하지만 문제를 생각할수록, 캐싱 + 분산 환경 대응 + TTL 기반 중복 방지 측면에서 Redis가 대안이라고 판단했다.

Redis를 조회수 임시 저장소로 활용하되, 책임을 명확히 분리하기로 했다.

| 고민 | 선택 | 이유 |
| --- | --- | --- |
| 중복 방지 기준 | 회원 ID | 가장 정확하고, 간단 |
| TTL | 1시간 | 너무 짧으면 무의미, 너무 길면 UX 저하 |
| Redis 구조 | String + Set + ZSet | 키별로 명확하게 기능 분리 |
| 실시간 반영 방식 | Redis INCR | 즉시 조회수 증가, 성능 부담 없음 |

### 아키텍처 설계

```java
// 1. 조회수 관련 책임을 별도 서비스로 분리
@Service
public class ArticleViewService {
    // 조회수 증가, 중복 방지, 동기화 로직
}

// 2. Redis 키 관리를 별도 유틸리티로 중앙화
@NoArgsConstructor(access = AccessLevel.PRIVATE)
public class RedisKey {
    // Redis 키 패턴 통합 관리
}

// 3. 기존 ArticleService는 조회 로직에만 집중
@Service
public class ArticleService {
    private final ArticleViewService articleViewService;  // 조회수 처리 위임
    
    public ArticleDetailResponse findDetail(Long articleId, Long memberId) {
        // 게시글 조회만 담당
        // 조회수 처리는 ArticleViewService에 위임
    }
}
```

<br/>

## Redis 도입과 중복 방지 구현

가장 고민했던 부분: *중복 조회를 어떻게 방지할 것인가?*

```java
"중복 방지를 어떻게 할까?"
```

- IP 기준? → 공용 네트워크(회사, 카페)에서 문제가 있다.
- 세션 기준? → 쿠키 삭제하면 우회 가능, 구현 복잡하다.
- 회원 기준? → 정확하고 구현 간단하다. → (결정)
- 비로그인 사용자? → 일단 제외, 향후 확장 가능하게 설계

```java
"TTL을 얼마로 설정할까?"
```

- 10분?
  - 너무 짧다. 예를 들어, 사용자가 같은 글을 30분 간격으로 두 번 본 경우 조회수가 2회 증가하게 된다.
  - 중복 방지 측면에서 의미가 약해진다.
- 24시간?
  - 하루 동안 한 번만 조회된다고 판단하는 건 너무 보수적이다. 실제 사용자 패턴 상, 하루에 같은 게시글을 여러 번 열어보는 경우도 많았다. (특히 댓글 확인 목적).
  - 이럴 경우 “왜 나는 분명히 다시 봤는데 조회수는 그대로지?”라는 혼란을 줄 수 있다.
- 1시간? (결정)
  - Redis 입장에서도 TTL 만료 후 자연스럽게 삭제되어 키 관리 부담이 크지 않다.
  - 실제 사용자의 브라우징 흐름: 하나의 글을 짧게는 수초~수십 분 동안 본 뒤, 다시 방문하는 경우는 대부분 1시간 이상 경과한다.

그렇기에 단기적으로 키 수가 많아지더라도, 자동 만료로 자연스럽게 회수되기 때문에 전체 캐시 부하가 증가하지 않고, 예측 가능한 메모리 사용량을 유지할 수 있다.

### 실제 구현 과정

```java
// Redis 키 관리 중앙화
@NoArgsConstructor(access = AccessLevel.PRIVATE)
public class RedisKey {
    private static final String ARTICLE_VIEW_PREFIX = "view:article:";
    private static final String ARTICLE_MEMBER_VIEW_PATTERN = "viewed:article:%s:member:%s";
    private static final String ARTICLE_RANKING_KEY = "ranking:article:";
    
    public static String articleViewKey(Long articleId) {
        return ARTICLE_VIEW_PREFIX + articleId;
    }
    
    public static String articleMemberViewKey(Long articleId, Long memberId) {
        return String.format(ARTICLE_MEMBER_VIEW_PATTERN, articleId, memberId);
    }
    
    public static String articleRanking() {
        return ARTICLE_RANKING_KEY;
    }
}

// 조회수 서비스 구현
@Service
@RequiredArgsConstructor
public class ArticleViewService {
    private final StringRedisTemplate redisTemplate;
    private final ArticleRepository articleRepository;
    
    public Long addViewAndCount(Long articleId, Long memberId, Long dbViewCount) {
        // 1. 회원 기반 중복 방지
        boolean isFirstVisit = addUniqueViewCount(articleId, memberId);
        
        // 2. 첫 방문이면 랭킹에도 반영
        if (isFirstVisit) {
            redisTemplate.opsForZSet().incrementScore(
                RedisKey.articleRanking(),
                articleId.toString(),
                1.0  // 조회수 1 증가
            );
        }
        
        // 3. 총 조회수 반환 (DB + Redis)
        return getTotalViewCount(articleId, dbViewCount);
    }
    
    public boolean addUniqueViewCount(Long articleId, Long memberId) {
        String memberViewKey = RedisKey.articleMemberViewKey(articleId, memberId);
        Boolean isFirstVisit = redisTemplate.opsForValue()
                .setIfAbsent(
                        memberViewKey,
                        "VIEWED",
                        3600,  // 1시간 TTL
                        TimeUnit.SECONDS
                );

        if (Boolean.TRUE.equals(isFirstVisit)) {
            // Redis 카운터 증가
            redisTemplate.opsForValue().increment(RedisKey.articleViewKey(articleId));
            return true;
        }
        return false;
    }
    
    public Long getTotalViewCount(Long articleId, Long dbViewCount) {
        String key = RedisKey.articleViewKey(articleId);
        String cachedCount = redisTemplate.opsForValue().get(key);
        
        if (cachedCount == null) {
            return dbViewCount;
        }
        return dbViewCount + Long.parseLong(cachedCount);
    }
}
```

적용 결과:

- 응답시간: 0.8초 → 0.35초 (56% 추가 개선)
- 중복 조회: 회원 기반으로 정확하게 방지
- 실시간성: 즉시 반영

<br/>

## 지연 동기화와 데이터 일관성 보장

Redis 캐싱은 성공했지만, Redis 데이터를 DB로 동기화하는 안전한 방법이 필요했다.

- Redis에서 DB로 동기화할 때 데이터 손실 없이 어떻게 할 것인가?

```java
"동기화할 키를 어떻게 찾을까?"
```

- KEYS 명령어?
  - 운영 환경에서는 Redis에 저장된 모든 키 중 특정 패턴과 일치하는 키를 순회하게 되는데, 이 과정은 O(N) 연산으로 전체 키 수에 비례해 성능이 저하된다.
  - 게다가 단일 스레드로 작동하는 Redis의 특성상, 이 명령어 하나가 전체 인스턴스를 블로킹시킬 수 있다.
- Set으로 추적? (결정)
  - 조회수 증가 시마다 해당 키를 별도의 Set에 등록해두면, 우리는 ‘변경된 키’만 명확하게 추적할 수 있다.
  - `O(1)`로 추가 가능하고 Set 자체를 통해 한 번에 모든 추적 대상 키만 조회할 수 있으며 키 삭제도 간단하다.
  - 즉, 추적용 Set을 사용하는 구조는 운영 환경에 안전하고, 성능도 예측 가능한 구조다.

```java
"동기화 주기를 얼마로 할까?"
```

- 1분?
  - Redis에는 카운트가 거의 없는데도 1분마다 flush 되면, DB에는 무의미한 업데이트가 지속 발생할 수 있다. 또한, Redis 키들이 TTL 기반이 아니기 때문에 flush 이후에도 Redis 키가 남아있게 되어 메모리 관리 부담이 커진다.
  - 실제로 JMeter 테스트 시, 짧은 flush 주기는 Redis 부하와 DB IOPS를 동시에 증가했다.
- 1시간?
  - 반대로 너무 길게 설정하면, Redis 재시작 시 아직 flush되지 않은 조회수가 날아갈 위험이 있다.
  - 인기글 랭킹 기능을 운영한다면, 1시간 동안 조회수 증가분이 반영되지 않아 UX가 떨어진다.
- 10분? (결정)ㅇ
  - 여러 실험 끝에 10분이 가장 적절한 타이밍이었다.
  - 사용자에게는 실시간성에 가까운 응답을 유지하면서, Redis TTL이나 랭킹 캐싱 주기와도 잘 맞고 DB에 대한 write 빈도도 10배 이상 감소시킬 수 있었다.
  - 또한 Redis 재시작이 있더라도 10분 정도의 조회수 손실은 랭킹 집계에 미치는 영향이 미미하다고 생각했다.

```java
"Race Condition은 어떻게 해결할까?"
```

- 단순 GET → DEL? 처음에는 이렇게 구현했었다.
  - GET으로 조회수 값을 읽고 → DEL로 삭제한 후 → 해당 값을 DB에 반영하는 구조.
  - 하지만 이 구조는 중간에 다른 요청이 끼어들 수 있는 구조였다.
  - 예를 들어, GET 이후 DB 업데이트 사이에 조회수가 하나 더 올라간다면? 그 데이터는 영영 사라진다.

- Lua Script? (결정)
  - Lua Script는 Redis 서버 내에서 실행되는 단일 원자 연산 블록이다.
  - GET과 DEL을 하나의 원자 트랜잭션처럼 묶을 수 있고 중간에 끼어드는 요청 없이 안전하게 조회수를 가져올 수 있다. 실제 운영 환경에서도 Redis Script는 가장 보편적인 Race Condition 해결책이다.
  - Redis가 제공하는 유일한 동시성 컨트롤 수단이라고 생각한다.

### Set 기반 추적 키 관리 시스템 구현

```java
@Service
@RequiredArgsConstructor
public class ArticleViewService {
    
    public boolean addUniqueViewCount(Long articleId, Long memberId) {
        String memberViewKey = RedisKey.articleMemberViewKey(articleId, memberId);
        Boolean isFirstVisit = redisTemplate.opsForValue()
                .setIfAbsent(memberViewKey, "VIEWED", 3600, TimeUnit.SECONDS);

        if (Boolean.TRUE.equals(isFirstVisit)) {
            String viewKey = RedisKey.articleViewKey(articleId);
            redisTemplate.opsForValue().increment(viewKey);
            
            // 동기화할 키를 Set에 추가하여 추적
            redisTemplate.opsForSet().add(RedisKey.viewTrackingKeySet(), viewKey);
            
            return true;
        }
        return false;
    }
    
    @Transactional
    @Scheduled(fixedRate = 600000) // 10분마다
    public void bulkUpdateViewCounts() {
        // 추적 중인 키들만 가져와서 처리
        Set<String> keys = redisTemplate.opsForSet().members(RedisKey.viewTrackingKeySet());
        if (keys == null || keys.isEmpty()) return;

        Map<Long, Long> pendingViewCounts = new HashMap<>();

        for (String key : keys) {
            // Lua Script로 원자적 처리
            consumeViewCount(key).ifPresent(countStr -> {
                Long articleId = RedisKey.getArticleIdFromKey(key);
                Long redisViewCount = Long.parseLong(countStr);
                pendingViewCounts.put(articleId, redisViewCount);
                
                // 처리 완료된 키는 추적 Set에서 제거
                redisTemplate.opsForSet().remove(RedisKey.viewTrackingKeySet(), key);
            });
        }

        // 배치로 DB 업데이트
        pendingViewCounts.forEach(articleRepository::bulkAddViewCount);
    }
    
    public Optional<String> consumeViewCount(String key) {
        // Lua Script로 GET과 DEL을 원자적으로 처리
        Object result = redisTemplate.execute(
                (RedisCallback<Object>) connection -> connection.eval(
                        RedisScripts.VIEW_COUNT_POP_SCRIPT.getBytes(),
                        ReturnType.VALUE,
                        1,  // 키 개수
                        key.getBytes()
                )
        );
        return Optional.ofNullable(result).map(Object::toString);
    }
}
```

### Lua Script 내용 (`RedisScripts.VIEW_COUNT_POP_SCRIPT`):

```java
local count = redis.call('GET', KEYS[1])
if count and tonumber(count) > 0 then
    redis.call('DEL', KEYS[1])
    return count
else
    return nil
end
```

<br/>

## 얼마나 개선되었는지?

![image.png](/static/images/이미지218.png)

성능 테스트 결과

```java
# 동일 조건 부하 테스트 결과

Before (DB 직접 업데이트):
- 평균 응답시간: 2,300ms
- 95%ile 응답시간: 4,500ms  
- 에러율: 15%
- DB CPU: 85%
- DB 커넥션 풀: 90% 사용
- 처리량: 43 req/sec

After (Redis 캐싱 + 지연 동기화):
- 평균 응답시간: 320ms (86% 개선)
- 95%ile 응답시간: 580ms (87% 개선)
- 에러율: 0.1% (99% 개선)
- DB CPU: 25% (70% 개선)
- DB 커넥션 풀: 30% 사용 (67% 개선)
- 처리량: 312 req/sec (625% 개선)
```

<br/>

## 마무리

이번 조회수 시스템 개선 과정은 단순히 성능 최적화를 넘어서, 확장 가능한 아키텍처 설계와 운영 중심의 사고를 배울 수 있는 값진 경험이었습니다.

2.3초에서 → 0.32초로 86% 성능 개선이라는 수치적 성과도 중요하지만, 더 중요한 것은 이 과정에서 배운 점진적 개선, 실용적 선택 등을 했던것 같습니다.

특히 "처음부터 완벽한 설계를 하려 하지 말고, 실제 문제에 집중해서 단계별로 해결해나가면서 더 나은 아키텍처로 발전시켜 나가는 것"이 실제 서비스 운영에서는 더 현실적인 접근법임을 깨달았습니다.

앞으로도 사용자 경험 개선과 시스템 안정성 확보를 위해 지속적으로 개선해나갈 예정입니다.